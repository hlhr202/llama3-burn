# llama3-burn (wgpu)

This is a random llama3 implemented using burn-rs. I used webgpu with full precision. It also supports loading safetensors.

## Usage

- Download model to "models" folder, I code this with [tiny-random-Llama3ForCausalLM](https://huggingface.co/HuggingFaceM4/tiny-random-Llama3ForCausalLM)
- run `cargo run`

## Credits

- I use the model implementation from [llama2-burn](https://github.com/Gadersd/llama2-burn)
